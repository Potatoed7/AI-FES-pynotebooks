{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# k-Means Clustering"],"metadata":{"id":"L-cT6ActPw_9"}},{"cell_type":"markdown","source":["First let's import the libraries will be using for this tutorial. We will be using matplotlib to plot our graphs, and sklearn for the dataset and k-Means."],"metadata":{"id":"0lT_kFYZGvWQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GQOxRG310rXH"},"outputs":[],"source":["# Library Imports\n","import numpy as np\n","import matplotlib.cm as cm\n","import matplotlib.pyplot as plt\n","from sklearn import datasets\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_samples, silhouette_score\n","from sklearn.preprocessing import MinMaxScaler"]},{"cell_type":"markdown","source":["**Step 1:**\n","\n","Once again we'll be using the Iris dataset, so loading it is simple. Let's quickly plot the dataset as well."],"metadata":{"id":"jBncygOuGus2"}},{"cell_type":"code","source":["# Load the Iris dataset from scikit-learn\n","iris = datasets.load_iris()\n","x = iris.data\n","y = iris.target\n","\n","# 3D Data Plot and Settings\n","def create_plot(x, y, title, group_label):\n","    fig = plt.figure()\n","    ax = fig.add_subplot(projection='3d')\n","    ax.scatter(x[:, 3], x[:, 0], x[:, 2], c=y.astype(float), edgecolor=\"k\")\n","\n","    ax.xaxis.set_ticklabels([])\n","    ax.yaxis.set_ticklabels([])\n","    ax.zaxis.set_ticklabels([])\n","    ax.set_xlabel(\"Petal width\")\n","    ax.set_ylabel(\"Sepal length\")\n","    ax.set_zlabel(\"Petal length\")\n","    ax.set_title(title)\n","    ax.xaxis.labelpad=-10\n","    ax.yaxis.labelpad=-10\n","    ax.zaxis.labelpad=-10\n","\n","    if group_label:\n","        for name, label in [(\"Setosa\", 0), (\"Versicolour\", 1), (\"Virginica\", 2)]:\n","            ax.text3D(\n","                x[y == label, 3].mean(),\n","                x[y == label, 0].mean(),\n","                x[y == label, 2].mean() + 2,\n","                name,\n","                horizontalalignment=\"center\",\n","                bbox=dict(alpha=0.2, edgecolor=\"w\", facecolor=\"w\"),\n","            )\n","\n","    plt.show()\n","\n","create_plot(x, y, \"Iris Dataset\", True)"],"metadata":{"id":"BGUwg4_CGzz2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 2:**\n","\n","Recall that our data can often contain variables of different magnitudes, such us some in tens and other in thousands. To calculate their distance, we can use normalisation to remap them to fix a range so each variable has an equal weight. In sklearn, we can use `sklearn.preprocessing.MinMaxScaler` to normalise the iris measurements to the range [0, 1], or any other range we want.\n"],"metadata":{"id":"ntTJRyTWlT5s"}},{"cell_type":"code","source":["# Check the first row of measurements before normalisation\n","print(x[0].round(2))\n","\n","# Normalise measurements to [0, 1]\n","min_max_scaler = MinMaxScaler()\n","x = min_max_scaler.fit_transform(iris.data)\n","\n","# Check the first row of measurements after normalisation\n","print(x[0].round(2))"],"metadata":{"id":"ClcIMXhB_ffQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step 3:**\n","\n","Now we can use the [sklearn.cluster.KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans) function to perform k-Means clustering and plot the results. (Notice how in the ouput graph, the clusters are switched around each time you re-run the cell. This is because k-Means only creates clusters and has no way of knowing which is which.)"],"metadata":{"id":"LuyjYHsITUNn"}},{"cell_type":"code","source":["# Create our k-Means model with k = 3\n","clusterer = KMeans(n_clusters=3)\n","# Fit the model to our data\n","clusterer.fit(x)\n","# Output clusters from our models\n","cluster_labels = clusterer.labels_\n","\n","# Draw 3D Plot\n","create_plot(x, cluster_labels, \"k-Means Clustering\", False)"],"metadata":{"id":"dTVBdQlg0xXk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Try adjusting some of the KMeans parameters and seeing how the results change:\n","\n","- n_clusters: k value, number of clusters that KMeans finds\n","- n_init: Number of times KMeans is run with different random centroid seeds, also known as k-Means++\n","- max_iter: Maximum iterations of KMeans for a run\n","- algorithm: Whether to use LLoyd's or Elkan's algorithm (depending on dataset, might have performance or runtime differences)"],"metadata":{"id":"eSTWFsQiUsx3"}},{"cell_type":"code","source":["n_clusters = 3\n","clusterer = KMeans(n_clusters=n_clusters, n_init=10, algorithm=\"elkan\")\n","clusterer.fit(x)\n","cluster_labels = clusterer.labels_\n","\n","create_plot(x, cluster_labels, \"k-Means Clustering\", False)"],"metadata":{"id":"2sxh248sGB8V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2tsrslD7nTdL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AcubQs97nTfl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nTP5KhlmnTiJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9ALW7gfonTmj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dKGGSVASnTqJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Silhouette Score\n","\n","**Silhouette score** is a way to measure how good clusters are. It ranges from -1 to 1. The higher the score, the more distinct the clusters are:\n","*    an average silhouette score of over 0.7 is considered to be \"strong\", a value over 0.5 \"reasonable\" and over 0.25 \"weak\"\n","*    For a specific point, it's silhouette score is directly proportional to its distance from the cluster's centroid.\n","*    To determine how good the clustering is, we can take the average silhouette score of all points.\n","\n","Thankfully we can use sklearn to automatically calculate the average silhouette score of a specific clustering.\n"],"metadata":{"id":"XLNMNq3i1TAn"}},{"cell_type":"code","source":["silhouette_avg = silhouette_score(x, cluster_labels)\n","print(f\"The average silhouette_score is {silhouette_avg:.3f}\")"],"metadata":{"id":"N7L3VTZoWew2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can plot the silhouette scores on a graph to view them. The red dotted line is the overall average silhouette score:"],"metadata":{"id":"sYl11Xic33R-"}},{"cell_type":"code","source":["fig = plt.figure()\n","ax = fig.add_subplot()\n","\n","# The silhouette coefficient can range from [-1, 1]\n","# but we can reduce the limits to maximise space usage\n","ax.set_xlim([-0.2, 1])\n","\n","# Compute the silhouette scores for each sample\n","sample_silhouette_values = silhouette_samples(x, cluster_labels)\n","\n","y_lower = 10\n","for i in range(n_clusters):\n","    # Get silhouette scores for each sample in cluster i and sort tehem\n","    ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n","    ith_cluster_silhouette_values.sort()\n","    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n","\n","    y_upper = y_lower + size_cluster_i\n","\n","    color = cm.nipy_spectral(float(i) / n_clusters)\n","    ax.fill_betweenx(\n","        np.arange(y_lower, y_upper),\n","        0,\n","        ith_cluster_silhouette_values,\n","        facecolor=color,\n","        edgecolor=color,\n","        alpha=0.7,\n","    )\n","\n","    # Label the silhouette plots\n","    ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n","\n","    # Compute the new y_lower for next plot\n","    y_lower = y_upper + 10\n","\n","ax.set_title(\"Silhouette plot for \" + str(n_clusters) + \" clusters\")\n","ax.set_xlabel(\"Silhouette coefficient values\")\n","ax.set_ylabel(\"Cluster label\")\n","ax.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n","ax.set_yticks([])\n","\n","# The vertical line for average silhouette score of all the values\n","ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n","\n","plt.show()"],"metadata":{"id":"NQq4Z3V8ckYa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can try different values of n_clusters, comparing their silhouette scores to see which is the most suitable value."],"metadata":{"id":"JeEW78A06iwt"}},{"cell_type":"code","source":["range_n_clusters = [2, 3, 4, 5]\n","silhouette_scores = []\n","best_n = 0\n","highest_score = -10.0\n","\n","# Do the plot for each value of n_clusters\n","for n_clusters in range_n_clusters:\n","    clusterer = KMeans(n_clusters=n_clusters, n_init=10, algorithm=\"elkan\")\n","    clusterer.fit(x)\n","    cluster_labels = clusterer.labels_\n","    silhouette_avg = silhouette_score(x, cluster_labels)\n","    silhouette_scores.append(silhouette_avg)\n","\n","    if silhouette_avg > highest_score:\n","        highest_score = silhouette_avg\n","        best_n = n_clusters\n","\n","    fig = plt.figure()\n","    ax = fig.add_subplot()\n","\n","    # The silhouette coefficient can range from [-1, 1]\n","    # but we can reduce the limits to maximise space usage\n","    ax.set_xlim([-0.2, 1])\n","\n","    # Compute the silhouette scores for each sample\n","    sample_silhouette_values = silhouette_samples(x, cluster_labels)\n","\n","    y_lower = 10\n","    for i in range(n_clusters):\n","        # Get silhouette scores for each sample in cluster i and sort tehem\n","        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n","        ith_cluster_silhouette_values.sort()\n","        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n","\n","        y_upper = y_lower + size_cluster_i\n","\n","        color = cm.nipy_spectral(float(i) / n_clusters)\n","        ax.fill_betweenx(\n","            np.arange(y_lower, y_upper),\n","            0,\n","            ith_cluster_silhouette_values,\n","            facecolor=color,\n","            edgecolor=color,\n","            alpha=0.7,\n","        )\n","\n","        # Label the silhouette plots\n","        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n","\n","        # Compute the new y_lower for next plot\n","        y_lower = y_upper + 10\n","\n","    ax.set_title(\"Silhouette plot for \" + str(n_clusters) + \" clusters\")\n","    ax.set_xlabel(\"Silhouette coefficient values\")\n","    ax.set_ylabel(\"Cluster label\")\n","    ax.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n","    ax.set_yticks([])\n","\n","    # The vertical line for average silhouette score of all the values\n","    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n","\n","    plt.show()\n","\n","# Output silhouette scores for each value along with best score\n","print(f\"The best average silhouette_score is {highest_score:.3f} using {best_n:.3f} clusters\")\n","for i, j in zip(range_n_clusters, silhouette_scores):\n","    print(f\"The average silhouette_score for {i} clusters is {j:.3f}\")\n"],"metadata":{"id":"jiLtY9cm3PKg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calculating the silhouette score for multiple k values allows us to compare and choose the best number of clusters for our dataset. In the above case, 2 clusters give us the best silhouette score and is the ideal number of clusters."],"metadata":{"id":"d178mN8Gp1Fp"}},{"cell_type":"code","source":[],"metadata":{"id":"cUcXEwC-7FwX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Qu_hGgaVgY5a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aMQmkUbpgY8J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Exercise: Clustering\n","\n","Let's try to implement clustering on a new dataset now. Feel free to search for your own dataset, or use the Mall Customer Dataset imported below. This dataset looks at the spending profiles of 200 mall customers.\n","\n","*    Hint1: the Gender column is non-numeric. What can you do about that?\n","*    Hint2: you can still normalise a dataframe using MinMaxScaler()"],"metadata":{"id":"7MrFXxM-gYCs"}},{"cell_type":"code","source":["import pandas as pd\n","data = pd.read_csv('https://raw.githubusercontent.com/iamamangosteen/aimlnotebooks/main/Mall_Customers.csv')\n","data.head()"],"metadata":{"id":"vE3rVBQygZ5W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8zVANumAktx7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xhq-lgyukt5l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cI-s-Bdskt7e"},"execution_count":null,"outputs":[]}]}